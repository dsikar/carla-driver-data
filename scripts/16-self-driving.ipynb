{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NVIDIANet(nn.Module):\n",
    "    def __init__(self, num_outputs=1, dropout_rate=0.1):\n",
    "        super(NVIDIANet, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 32, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 48, kernel_size=5, stride=2)\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1152, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input normalization\n",
    "        x = x / 255.0\n",
    "        \n",
    "        # Convolutional layers with ELU activation and dropout\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv5(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        x = self.flatten(x)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def load_model(model, model_path, device='cuda'):\n",
    "    \"\"\"Load a saved model\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import carla\n",
    "\n",
    "def set_spectator_camera_following_car(world, vehicle):\n",
    "\n",
    "    spectator = world.get_spectator()\n",
    "    transform = vehicle.get_transform()\n",
    "    location = transform.location\n",
    "    rotation = transform.rotation\n",
    "\n",
    "    offset_location = location - carla.Location(x=35 * math.cos(math.radians(rotation.yaw)),\n",
    "                                              y=35 * math.sin(math.radians(rotation.yaw)))\n",
    "    offset_location.z += 20\n",
    "\n",
    "    spectator.set_transform(carla.Transform(offset_location,\n",
    "                                          carla.Rotation(pitch=-15, yaw=rotation.yaw, roll=rotation.roll)))\n",
    "    return spectator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle and sensors initialized. Starting control loop...\n",
      "Stopping...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "class CarlaSteering:\n",
    "    def __init__(self, model_path='best_steering_model_v1.pth', host='localhost', port=2000, \n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize CARLA client\n",
    "        self.client = carla.Client(host, port)\n",
    "        self.client.set_timeout(10.0)\n",
    "        self.world = self.client.get_world()\n",
    "        \n",
    "        # Set synchronous mode with fixed time step\n",
    "        settings = self.world.get_settings()\n",
    "        settings.synchronous_mode = True\n",
    "        settings.fixed_delta_seconds = 0.1  # 10 FPS - slower rate for better synchronization\n",
    "        self.world.apply_settings(settings)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = NVIDIANet()\n",
    "        self.model = load_model(self.model, model_path, device)\n",
    "        \n",
    "        # Image queue for processing\n",
    "        self.image_queue = queue.Queue()\n",
    "        self.current_image = None\n",
    "        \n",
    "        # Control parameters\n",
    "        self.max_steering_angle = 1.0\n",
    "        self.steering_smoothing = 0.5\n",
    "        self.last_steering = 0.0\n",
    "        \n",
    "    def setup_vehicle(self):\n",
    "        \"\"\"Spawn and setup the ego vehicle with sensors\"\"\"\n",
    "        # Load Town04\n",
    "        self.client.load_world('Town04')\n",
    "        self.world = self.client.get_world()\n",
    "        \n",
    "        # Get specific spawn point from route 35, lane -3\n",
    "        waypoints = self.world.get_map().generate_waypoints(2.0)  # 2.0 is the distance between waypoints\n",
    "        route_35_waypoints = [w for w in waypoints if w.road_id == 35 and w.lane_id == -3]\n",
    "        if not route_35_waypoints:\n",
    "            raise ValueError(\"Could not find waypoints for route 35, lane -3\")\n",
    "        \n",
    "        # Get the first waypoint and create a spawn point\n",
    "        first_waypoint = route_35_waypoints[0]\n",
    "        # Create spawn point and lift it by 1 unit to avoid collision\n",
    "        spawn_location = first_waypoint.transform.location\n",
    "        spawn_location.z += 1  # Lift vehicle 1 unit up to avoid collision\n",
    "        spawn_point = carla.Transform(\n",
    "            spawn_location,\n",
    "            first_waypoint.transform.rotation\n",
    "        )\n",
    "        \n",
    "        # Spawn vehicle\n",
    "        blueprint_library = self.world.get_blueprint_library()\n",
    "        vehicle_bp = blueprint_library.filter('model3')[0]\n",
    "        self.vehicle = self.world.spawn_actor(vehicle_bp, spawn_point)\n",
    "        \n",
    "        # Spawn camera\n",
    "        camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "        camera_bp.set_attribute('image_size_x', '800')\n",
    "        camera_bp.set_attribute('image_size_y', '600')\n",
    "        camera_bp.set_attribute('fov', '90')\n",
    "        \n",
    "        # Attach camera to vehicle\n",
    "        camera_spawn_point = carla.Transform(carla.Location(x=2.0, z=1.4))\n",
    "        self.camera = self.world.spawn_actor(camera_bp, camera_spawn_point, attach_to=self.vehicle)\n",
    "        self.camera.listen(self.process_image)\n",
    "        \n",
    "    def process_image(self, image):\n",
    "        \"\"\"Callback to process images from CARLA camera\"\"\"\n",
    "        # Convert CARLA image to numpy array\n",
    "        img = np.array(image.raw_data).reshape((600, 800, 4))\n",
    "        img = img[:, :, :3]  # Remove alpha channel\n",
    "        \n",
    "        # Store in queue\n",
    "        self.image_queue.put(img)\n",
    "        \n",
    "    def preprocess_image(self, img):\n",
    "        \"\"\"Preprocess image for neural network\"\"\"\n",
    "        # Store original image for display\n",
    "        self.original_img = img.copy()\n",
    "        \n",
    "        # Crop\n",
    "        cropped = img[260:440, :]\n",
    "        \n",
    "        # Resize\n",
    "        resized = cv2.resize(cropped, (200, 66))\n",
    "        \n",
    "        # Convert to YUV\n",
    "        yuv = cv2.cvtColor(resized, cv2.COLOR_RGB2YUV)\n",
    "        \n",
    "        # Store preprocessed image for display\n",
    "        self.preprocessed_img = yuv.copy()\n",
    "        \n",
    "        # Prepare for PyTorch (CHW format)\n",
    "        yuv = yuv.transpose((2, 0, 1))\n",
    "        yuv = np.ascontiguousarray(yuv)\n",
    "        \n",
    "        return torch.from_numpy(yuv).float().unsqueeze(0).to(self.device)\n",
    "        \n",
    "    def display_images(self):\n",
    "        \"\"\"Display original and preprocessed images side by side\"\"\"\n",
    "        if hasattr(self, 'original_img') and hasattr(self, 'preprocessed_img'):\n",
    "            # Resize original image to be similar height as preprocessed\n",
    "            display_height = 264  # 4x preprocessed height\n",
    "            aspect_ratio = self.original_img.shape[1] / self.original_img.shape[0]\n",
    "            display_width = int(display_height * aspect_ratio)\n",
    "            original_resized = cv2.resize(self.original_img, (display_width, display_height))\n",
    "            \n",
    "            # Resize preprocessed image for better visibility\n",
    "            preprocessed_display = cv2.resize(self.preprocessed_img, (800, 264))  # 4x original size\n",
    "            \n",
    "            # Create a black canvas for side-by-side display\n",
    "            canvas_width = display_width + 800 + 20  # +20 for padding\n",
    "            canvas = np.zeros((display_height, canvas_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            # Place images on canvas\n",
    "            canvas[:, :display_width] = original_resized\n",
    "            canvas[:, display_width+20:] = preprocessed_display\n",
    "            \n",
    "            # Add labels\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(canvas, 'Original Camera Feed', (10, 30), font, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(canvas, 'Neural Network Input (YUV)', (display_width+30, 30), font, 1, (255, 255, 255), 2)\n",
    "            \n",
    "            # Show the canvas\n",
    "            cv2.imshow('Camera Views', canvas)\n",
    "            cv2.waitKey(1)\n",
    "        \n",
    "    def predict_steering(self, image):\n",
    "        \"\"\"Make steering prediction from image\"\"\"\n",
    "        with torch.no_grad():\n",
    "            steering_pred = self.model(image)\n",
    "            \n",
    "        # Get steering angle from prediction\n",
    "        steering_angle = float(steering_pred.cpu().numpy()[0, 0])\n",
    "        \n",
    "        # Clip and smooth steering\n",
    "        steering_angle = np.clip(steering_angle, -self.max_steering_angle, self.max_steering_angle)\n",
    "        # smoothed_steering = (self.steering_smoothing * self.last_steering + \n",
    "                           #(1 - self.steering_smoothing) * steering_angle)\n",
    "        self.last_steering = steering_angle # smoothed_steering\n",
    "        \n",
    "        return steering_angle # smoothed_steering\n",
    "        \n",
    "    def apply_control(self, steering):\n",
    "        \"\"\"Apply steering control to vehicle\"\"\"\n",
    "        control = carla.VehicleControl()\n",
    "        control.steer = steering\n",
    "        control.throttle = 0.5  # Constant throttle for now\n",
    "        self.vehicle.apply_control(control)\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Main control loop\"\"\"\n",
    "        try:\n",
    "            self.setup_vehicle()\n",
    "            print(\"Vehicle and sensors initialized. Starting control loop...\")\n",
    "            \n",
    "            while True:\n",
    "                # Clear the image queue to always use latest frame\n",
    "                while not self.image_queue.empty():\n",
    "                    _ = self.image_queue.get()\n",
    "                \n",
    "                # Tick the world and wait for new image\n",
    "                self.world.tick()\n",
    "                \n",
    "                try:\n",
    "                    # Wait for new image with timeout\n",
    "                    img = self.image_queue.get(timeout=0.1)\n",
    "                    \n",
    "                    # Preprocess image\n",
    "                    processed_img = self.preprocess_image(img)\n",
    "                    \n",
    "                    # Get steering prediction\n",
    "                    steering = self.predict_steering(processed_img)\n",
    "                    \n",
    "                    # Apply control\n",
    "                    self.apply_control(steering)\n",
    "                    \n",
    "                    # Update spectator camera\n",
    "                    set_spectator_camera_following_car(self.world, self.vehicle)\n",
    "                    \n",
    "                    # Display camera feeds\n",
    "                    self.display_images()\n",
    "                    \n",
    "                    #print(f\"Applied steering angle: {steering:.3f}\")\n",
    "                    \n",
    "                except queue.Empty:\n",
    "                    print(\"Warning: Frame missed!\")\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopping...\")\n",
    "        finally:\n",
    "            # Cleanup\n",
    "            settings = self.world.get_settings()\n",
    "            settings.synchronous_mode = False\n",
    "            self.world.apply_settings(settings)\n",
    "            \n",
    "            if hasattr(self, 'camera'):\n",
    "                self.camera.destroy()\n",
    "            if hasattr(self, 'vehicle'):\n",
    "                self.vehicle.destroy()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        controller = CarlaSteering()\n",
    "        controller.run()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "# Create a CARLA client\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "# Get the world object\n",
    "world = client.get_world()\n",
    "# Get all the actors in the world\n",
    "actors = world.get_actors()\n",
    "\n",
    "# Filter the actors to get only the vehicles\n",
    "vehicles = [actor for actor in actors if 'vehicle' in actor.type_id]\n",
    "\n",
    "# Print the list of vehicles\n",
    "for vehicle in vehicles:\n",
    "    print(vehicle)\n",
    "# transform = vehicle.get_transform()\n",
    "\n",
    "# # Get the location from the transform\n",
    "# location = transform.location\n",
    "\n",
    "# # Print the location\n",
    "# print(f\"Vehicle location: x={location.x}, y={location.y}, z={location.z}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
