{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15306 valid files\n",
      "Split into 12245 training and 3061 validation samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def get_carla_data_files(data_dir: str, min_timestamp: str = \"20241209_173218_948893\") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Get all valid training files from the Carla dataset directory and their steering angles.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the carla_dataset directory\n",
    "        min_timestamp: Minimum timestamp to include (as string)\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing (file_path, steering_angle)\n",
    "    \"\"\"\n",
    "    # Get all jpg files in directory\n",
    "    pattern = os.path.join(data_dir, \"*.jpg\")\n",
    "    all_files = glob.glob(pattern)\n",
    "    \n",
    "    valid_files = []\n",
    "    for file_path in all_files:\n",
    "        # Get filename without extension\n",
    "        filename = os.path.basename(file_path)\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        # Check if filename matches expected pattern\n",
    "        if len(parts) >= 5 and 'steering' in filename:\n",
    "            # Extract timestamp and steering\n",
    "            timestamp = '_'.join(parts[0:3])  # Combine timestamp parts\n",
    "            try:\n",
    "                steering = float(parts[-1].replace('.jpg', ''))\n",
    "                \n",
    "                # Only include files with timestamp >= min_timestamp\n",
    "                if timestamp >= min_timestamp:\n",
    "                    valid_files.append((file_path, steering))\n",
    "            except ValueError:\n",
    "                continue  # Skip if steering value can't be converted to float\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    valid_files.sort(key=lambda x: os.path.basename(x[0]).split('_')[0:3])\n",
    "    \n",
    "    return valid_files\n",
    "\n",
    "def train_val_split(file_pairs: List[Tuple[str, float]], val_ratio: float = 0.2) -> Tuple[List[Tuple[str, float]], List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training and validation sets.\n",
    "    \n",
    "    Args:\n",
    "        file_pairs: List of (file_path, steering_angle) tuples\n",
    "        val_ratio: Ratio of validation set size to total dataset size\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_pairs, val_pairs)\n",
    "    \"\"\"\n",
    "    # Create random indices\n",
    "    num_samples = len(file_pairs)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    split_idx = int(np.floor(val_ratio * num_samples))\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    val_indices = indices[:split_idx]\n",
    "    train_indices = indices[split_idx:]\n",
    "    \n",
    "    train_pairs = [file_pairs[i] for i in train_indices]\n",
    "    val_pairs = [file_pairs[i] for i in val_indices]\n",
    "    \n",
    "    return train_pairs, val_pairs\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the functions\n",
    "    data_dir = \"carla_dataset\"\n",
    "    files = get_carla_data_files(data_dir)\n",
    "    print(f\"Found {len(files)} valid files\")\n",
    "    \n",
    "    train_files, val_files = train_val_split(files)\n",
    "    print(f\"Split into {len(train_files)} training and {len(val_files)} validation samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "class CarlaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Carla steering angle prediction.\n",
    "    Handles loading and preprocessing of images, and conversion to tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 file_pairs: List[Tuple[str, float]], \n",
    "                 crop_top: int = 260,\n",
    "                 crop_bottom: int = 440,\n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            file_pairs: List of tuples containing (image_path, steering_angle)\n",
    "            crop_top: Y coordinate where crop begins\n",
    "            crop_bottom: Y coordinate where crop ends\n",
    "            transform: Optional additional transformations\n",
    "        \"\"\"\n",
    "        self.file_pairs = file_pairs\n",
    "        self.crop_top = crop_top\n",
    "        self.crop_bottom = crop_bottom\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_pairs)\n",
    "    \n",
    "    def prepare_image_for_neural_network(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Load image, crop, resize, and convert to YUV for neural network processing.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the input image\n",
    "            \n",
    "        Returns:\n",
    "            numpy array in YUV format, size 66x200x3\n",
    "        \"\"\"\n",
    "        # Read and convert image\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Crop\n",
    "        cropped = img_rgb[self.crop_top:self.crop_bottom, :]\n",
    "        \n",
    "        # Resize to neural network input size (66x200)\n",
    "        resized = cv2.resize(cropped, (200, 66))\n",
    "        \n",
    "        # Convert to YUV\n",
    "        yuv = cv2.cvtColor(resized, cv2.COLOR_RGB2YUV)\n",
    "        \n",
    "        return yuv\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get a sample from the dataset.\n",
    "        \n",
    "        Args:\n",
    "            idx: Index of the sample to get\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (image, steering_angle) where image is a preprocessed torch tensor\n",
    "                  and steering_angle is a torch tensor\n",
    "        \"\"\"\n",
    "        image_path, steering_angle = self.file_pairs[idx]\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = self.prepare_image_for_neural_network(image_path)\n",
    "        \n",
    "        # Convert to torch tensor and adjust dimensions for PyTorch (CHW instead of HWC)\n",
    "        image_tensor = torch.from_numpy(image).float()\n",
    "        image_tensor = image_tensor.permute(2, 0, 1)  # Change from HWC to CHW format\n",
    "        \n",
    "        # Convert steering angle to tensor\n",
    "        steering_tensor = torch.tensor(steering_angle, dtype=torch.float32)\n",
    "        \n",
    "        # Apply any additional transforms if specified\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image_tensor)\n",
    "            \n",
    "        return image_tensor, steering_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 15306\n",
      "Training samples: 12245, Validation samples: 3061\n",
      "Batch image shape: torch.Size([64, 3, 66, 200])\n",
      "Batch steering shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Example usage in Jupyter notebook:\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Get file pairs\n",
    "data_dir = \"carla_dataset\"  # adjust path as needed\n",
    "file_pairs = get_carla_data_files(data_dir)\n",
    "print(f\"Total number of samples: {len(file_pairs)}\")\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_pairs, val_pairs = train_val_split(file_pairs)\n",
    "print(f\"Training samples: {len(train_pairs)}, Validation samples: {len(val_pairs)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CarlaDataset(train_pairs)\n",
    "val_dataset = CarlaDataset(val_pairs)\n",
    "\n",
    "# Create dataloaders with appropriate num_workers for Jupyter\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)  # num_workers=0 for Jupyter\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "# Test loading a single batch\n",
    "images, steering = next(iter(train_loader))\n",
    "print(f\"Batch image shape: {images.shape}\")  # Should be [batch_size, 3, 66, 200]\n",
    "print(f\"Batch steering shape: {steering.shape}\")  # Should be [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NVIDIANet(nn.Module):\n",
    "    def __init__(self, num_outputs=1, dropout_rate=0.1):\n",
    "        super(NVIDIANet, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 32, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 48, kernel_size=5, stride=2)\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1152, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input normalization\n",
    "        x = x / 255.0\n",
    "        \n",
    "        # Convolutional layers with ELU activation and dropout\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv5(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        x = self.flatten(x)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_state_dict = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_state_dict = model.state_dict().copy()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_state_dict = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "            return True  # Indicates we have a new best model\n",
    "        return False  # Indicates this is not a new best model\n",
    "\n",
    "def train_model(model, train_loader, val_loader, model_save_path, num_epochs=100, device=\"cuda\", learning_rate=1e-5):\n",
    "    \"\"\"Training loop with validation and early stopping\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    early_stopping = EarlyStopping(patience=6)\n",
    "    \n",
    "    # History for plotting\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for images, steering in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images = images.to(device)\n",
    "            steering = steering.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), steering)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, steering in val_loader:\n",
    "                images = images.to(device)\n",
    "                steering = steering.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs.squeeze(), steering)\n",
    "                val_losses.append(val_loss.item())\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        \n",
    "        # Save to history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        is_best = early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        # Save if it's the best model\n",
    "        if is_best:\n",
    "            print(f\"New best model! Saving to {model_save_path}\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "            }, model_save_path)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            print(f\"Loading best model from {model_save_path}\")\n",
    "            model.load_state_dict(early_stopping.best_state_dict)\n",
    "            break\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def load_model(model, model_path, device='cuda'):\n",
    "    \"\"\"Load a saved model\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss During Training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def train_steering_model(train_dataset, val_dataset, model_save_path, batch_size=64):\n",
    "    \"\"\"Full training pipeline\"\"\"\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = NVIDIANet(num_outputs=1)\n",
    "    \n",
    "    # Train model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    trained_model, history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        model_save_path=model_save_path,\n",
    "        num_epochs=100,\n",
    "        device=device,\n",
    "        learning_rate=1e-5\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return trained_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdafe79a15f4c3f9d7c442abee66d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.0135, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ff2385c0d5418a8fe904ff8a73ad7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.0004, Val Loss: 0.0003\n",
      "New best model! Saving to best_steering_model_v1.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c53f4452984806ba999493212bb66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 0.0004, Val Loss: 0.0003\n",
      "New best model! Saving to best_steering_model_v1.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5774e8deb37344b0b56e15bd7e41fd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 0.0004, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bab27dc5b6d475fa2b2d8d70ad9b804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.0004, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83508218fec748b49c339257dafcc591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 0.0004, Val Loss: 0.0003\n",
      "New best model! Saving to best_steering_model_v1.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e2eafd45de4e38a343ba7ec77ce422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 0.0004, Val Loss: 0.0003\n",
      "New best model! Saving to best_steering_model_v1.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec09d3e3839443229e66a328fbca8290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 0.0004, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa47971d6eb4bb7b54791ee11c163a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 0.0004, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911a791e91584a3da630d1c980792884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0004, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93219079a1394c7da7c2f45bf24d38ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 0.0004, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f1e7a68e01490ebd80e8fd68753470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 0.0004, Val Loss: 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8f83c446a441b99723270008b32f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/100:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 0.0004, Val Loss: 0.0003\n",
      "Early stopping triggered\n",
      "Loading best model from best_steering_model_v1.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAGDCAYAAAB5rSfRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9mElEQVR4nO3dfXxdZZnv/8+VpE/ZfaDdGyo0NTtIAUtbWghFQSUVD4IwFgW0/cFIlR8IPx6Uc2YEZkZwGDrC/JjB4Qh6UBAGGAoyyimHIioQ0GEECvJUoFKb1KZUaNqSNn1Ocp0/1kq6s7uT5mGt7Oy9v+/XK6+ufa97rXXteyfplXutdS1zd0RERERkeCvLdwAiIiIisn9K2kREREQKgJI2ERERkQKgpE1ERESkAChpExERESkAStpERERECoCSNhGJlJmlzczNrKIPfReZ2W+HIq7hwMxazezQfMfREzM718x+GXVfEYmGkjaREmZmjWa228xSWe2/DxOvdJ5C61fyF8OxG81sh5ltNbMPzOw5M7vYzAb1O9Pdx7r76qjiBDCzH4bJYGv4We7JeP14P+O7391PibqviERDSZuINAALO1+Y2UygMn/hDBt/4e7jgGrgRuAq4M6B7CjOxNPdLw6TwbHAPwIPdr5299OGIgYRGRpK2kTkXuArGa/PB/4ts4OZTTCzfzOzDWa2xsz+rnPWyczKzexmM2s2s9XA6Tm2vdPM1pvZOjO7wczKBxOwmR1iZkvNbJOZrTKzCzPWzTWz5Wa2xczeM7N/CdtHm9l9ZrYxnD170cwm7+9Y7t7i7kuBLwPnm9mMcH/1Zvb/Zhy326necJbwUjN7B3gno+2wcPluM7vNzB4LZ/SeN7OPZGx/ipmtNLMWM7vdzJ7JPF4fx6nRzK4ys9eAbWZWYWZXm9kfw2O+aWZf2M97uNjM3gnH7DYzswH0LTezfw6/RxrM7LJ8zaKKFDIlbSLyO2C8mX00TKYWAPdl9fmfwATgUOAkgiTvq+G6C4EzgDlALXB21rZ3A23AYWGfU4B+JR85LAGagEPC4/2jmX06XPevwL+6+3jgI8BDYfv54XuYCiSBi4EdfT2gu78QHvOT/YjzTOB4YHoP6xcAfw9MBFYBiwHC09UPA9eEsa4ETujHcTMtJEikD3D3NuCPBO9hQnjs+8zs4F62PwM4DpgFfAn47AD6XgicBswGjiEYFxHpJyVtIgJ7Z9v+G/AWsK5zRUYid427b3X3RuCfgb8Mu3wJ+J67r3X3TcB3M7adDHwO+Ka7b3P394Fbwv0NiJlNBU4ErnL3ne7+CvBj9s4W7gEOM7OUu7e6++8y2pPAYe7e7u4vufuWfh7+XWBSP/p/1903uXtPyeHP3f2FMJm6nyCpgWDMVrj7z8J1twJ/7mesnW4NP5sdAO7+U3d/19073P1BglnAub1sf6O7f+DufwKezoixP32/RJBIN7n7ZoLTzSLST0raRASCpO3/ARaRdWoUSAEjgDUZbWuAKeHyIcDarHWdqsNt14enzD4A/hdw0CBiPQTY5O5be4jnAuBw4O3wFOgZYfu9wBPAEjN718z+ycxG9PPYU4BN/ei/dj/rMxOx7cDYcLnbmLq7E8zyDUS3GMzsK2b2SsbnMYPgM+5vjP3pm/09sr9xEZEclLSJCO6+huCGhM8BP8ta3UwwS1Wd0fZh9s7GrSc45Zi5rtNaYBeQcvcDwq/x7n7UIMJ9F5hkZuNyxePu77j7QoLE8CbgYTNLuPsed/97d59OcKrxDLpfy9crMzuOIGnrvI5rG91v2PhQjs28r/vPsh6oyji2Zb7up64YzKwa+BFwGZB09wOANwAb4L77qtv7ofv3i4j0kZI2Eel0AfBpd9+W2eju7QTXhS02s3Hhf/z/nb3XvT0EXGFmVWY2Ebg6Y9v1wC+Bfzaz8WZWZmYfMbOT+hHXqPAmgtFmNpogOXsO+G7YNiuM/T4AMzvPzA509w7gg3AfHWY2z8xmhqd7txAkoh37O3gY9xkE19Hd5+6vh6teAb5oZpXhzQUX9OM97c9jwEwzOzO8WP9ScieF/ZUgSOI2AJjZVwlm2uL2EPANM5tiZgcQ3IkrIv2kpE1EAHD3P7r78h5WX04ws7SaYKbp34G7wnU/Ijjt+CrwMvvO1H0FGAm8CWwmuMC+twvfs7US3DDQ+fVpgovr0wSzbj8HrnP3X4f9TwVWmFkrwU0JC8LruT4UHnsLwXV7zxCcMu3Jo2a2lWC28G+Bf2HvzRcQXJu3G3gPuIfgmrRIuHszcA7wT8BGghsZlhPMWg5mv28SXI/4XwRxzwT+c1DB9s2PCJL314DfA8sIbk5pH4JjixQNCy6VEBGR4cqC8ipNwLnu/nS+4xksMzsN+KG7V++3s4h00UybiMgwZGafNbMDzGwU8DcE1539bj+bDUtmNsbMPhfWiZsCXEcwQyoi/aCkTURkePo4QU21ZuAvgDN7KR0y3BlBTbjNBKdH3wKuzWtEIgVIp0dFRERECoBm2kREREQKgJI2ERERkQJQEg/rTaVSnk6nYz3Gtm3bSCQSsR6j1GhMo6XxjJ7GNFoaz+hpTKM1VOP50ksvNbv7gdntsSZtZnYqQZ2kcuDH7n5j1vpRBI/MOZagFtGX3b3RzJIE9ZSOA+5298ty7HspcKi777cwZDqdZvnynspPRaO+vp66urpYj1FqNKbR0nhGT2MaLY1n9DSm0Rqq8TSzNbnaYzs9GlYdvw04jaAw5EIzm57V7QJgs7sfRlCo8qawfSfwbeCvetj3FwkKboqIiIiUhDivaZsLrHL31e6+m+ARMPOz+swnqCQOwczayWZm7r7N3X9LkLx1Y2ZjCR6hc0N8oYuIiIgML3GeHp1C8PiXTk3A8T31cfc2M2sBkgR1iXryDwSPYdne28HN7CLgIoDJkydTX1/fn9j7rbW1NfZjlBqNabQ0ntHTmEZL4xk9jWm08j2eBXUjgpnNBj7i7leaWbq3vu5+B3AHQG1trcd9DlrXDURPYxotjWf0NKbR0ngO3J49e2hqamLnzu4nqCZMmMDo0aPzFFXxiXo8R48eTVVVFSNGjOhT/ziTtnXA1IzXVWFbrj5NZlYBTCC4IaEnHwdqzayRIPaDzKze3euiClpERKTQNDU1MW7cONLpNGbW1b5161bGjRuXx8iKS5Tj6e5s3LiRpqYmampq+rRNnNe0vQhMM7MaMxsJLACWZvVZCpwfLp8NPOW9PKLB3X/g7oe4exr4BPAHJWwiIlLqdu7cSTKZ7JawyfBmZiSTyX1mR3sT20xbeI3aZcATBCU/7nL3FWZ2PbDc3ZcCdwL3mtkqYBNBYgdAOJs2HhhpZmcCp7j7m3HFKyIiUsiUsBWe/n5msT4Rwd2Xufvh7v4Rd18ctl0bJmy4+053P8fdD3P3ue6+OmPbtLtPcvex7l6VnbC5e2NfarSJiIhIvDZu3Mjs2bOZPXs2H/rQh5gyZUrX6927d/e67fLly7niiiv2e4wTTjghkljr6+s544wzItnXUCuoGxFERERk+Ekmk7zyyisAfOc732Hs2LH81V/tLbXa1tZGRUXulKO2tpba2tr9HuO5556LJNZCpmePioiISOQWLVrExRdfzPHHH8+3vvUtXnjhBT7+8Y8zZ84cTjjhBFauXAl0n/n6zne+w9e+9jXq6uo49NBDufXWW7v2N3bs2K7+dXV1nH322Rx55JGce+65dF4Ov2zZMo488kiOPfZYrrjiin7NqD3wwAPMnDmTGTNmcNVVVwHQ3t7OokWLmDFjBjNnzuT73/8+ALfeeivTp09n1qxZLFiwoLfdRkozbSIiIkXk7x9dwZvvbgGCpKO8vHzQ+5x+yHiu+4uj+r1dU1MTzz33HOXl5WzZsoXf/OY3VFRU8Otf/5q/+Zu/4T/+4z/22ebtt9/m6aefZuvWrRxxxBFccskl+5TE+P3vf8+KFSs45JBDOPHEE/nP//xPamtr+frXv86zzz5LTU0NCxcu7HOc7777LldddRUvvfQSEydO5JRTTuGRRx5h6tSprFu3jjfeeAOAtWuD8rM33ngjDQ0NjBo1ig8++KDf4zJQmmmLwFvrt/D2pvZ8hyEiIjKsnHPOOV1JY0tLC+eccw4zZszgyiuvZMWKFTm3Of300xk1ahSpVIqDDjqI9957b58+c+fOpaqqirKyMmbPnk1jYyNvv/02hx56aFf5jP4kbS+++CJ1dXUceOCBVFRUcO655/Lss89y6KGHsnr1ai6//HJ+8YtfMH78eABmzZrFueeey3333dfjad84aKYtAv/8yz/w9tpdXPzFfEciIiKlLnNGLN912hKJRNfyt7/9bebNm8fPf/5zGhsbeyykPGrUqK7l8vJy2traBtQnChMnTuTVV1/liSee4Ic//CH3338/9957L4899hjPPvssjz76KIsXL+b1118fkuRNM20RqElV8t52p6OjxxJzIiIiJa2lpYUpU6YAcPfdd0e+/yOOOILVq1fT2NgIwIMPPtjnbefOncszzzxDc3Mz7e3tPPDAA5x00kk0NzfT0dHBWWedxQ033MCrr75KR0cHa9euZd68edx00020tLTQ2toa+fvJRTNtEahOJtjTAX/espNDDhiT73BERESGnW9961ucf/753HDDDZx++umR73/MmDHcfvvtnHrqqSQSCY477rge+z755JNUVVV1vf7pT3/KjTfeyLx583B3Tj/9dObPn8+rr77KV7/6VTo6OgC47rrraG9v57zzzqOlpQV354orruCAAw6I/P3kYr08gKBo1NbW+vLly2Pb/3+uaubcHz/Pv194PCd8JBXbcUqNnkMYLY1n9DSm0dJ4Dtxbb73FRz/60X3a8316dKi1trYyduxY3J1LL72UadOmceWVV0a2/zjGM9dnZ2Yvufs+dVB0ejQC6VRwzr6xeXueIxERESldP/rRj5g9ezZHHXUULS0tfP3rX893SJHS6dEIHDx+NBVl0LhxW75DERERKVlXXnllpDNrw41m2iJQVmYcVGk0NitpExERkXgoaYvI5MoyzbSJiIhIbJS0RWRypbFm43aV/RAREZFYKGmLyOTKMna1dbB+y858hyIiIiJFSElbRCYngqFco+vaRESkxMybN48nnniiW9v3vvc9Lrnkkh63qauro7Mc1+c+97mcz/D8zne+w80339zrsR955BHefPPNrtfXXnstv/71r/sRfW6ZD7IfLpS0RWRypQHQoOvaRESkxCxcuJAlS5Z0a1uyZEmfn/+5bNmyAReozU7arr/+ej7zmc8MaF/DnZK2iEwcbYyqKNMdpCIiUnLOPvtsHnvsMXbv3g1AY2Mj7777Lp/85Ce55JJLqK2t5aijjuK6667LuX06naa5uRmAxYsXc/jhh/OJT3yClStXdvX50Y9+xHHHHcfRRx/NWWedxfbt23nuuedYunQpf/3Xf83s2bP54x//yKJFi3j44YeB4MkHc+bMYebMmXzta19j165dXce77rrrOOaYY5g5cyZvv/12n9/rAw88wMyZM5kxYwZXXXUVAO3t7SxatIgZM2Ywc+ZMbrnlFgBuvfVWpk+fzqxZs1iwYEE/R3VfqtMWkTIzqpOVNG5UgV0REcmjx6+GP78OwJj2NiiP4L/6D82E027scfWkSZOYO3cujz/+OPPnz2fJkiV86UtfwsxYvHgxkyZNor29nZNPPpnXXnuNWbNm5dzPSy+9xJIlS3jllVdoa2vjmGOO4dhjjwXgi1/8IhdeeCEAf/d3f8edd97J5Zdfzuc//3nOOOMMzj777G772rlzJ4sWLeLJJ5/k8MMP5ytf+Qo/+MEP+OY3vwlAKpXi5Zdf5vbbb+fmm2/mxz/+8X6HYf369Vx11VW89NJLTJw4kVNOOYVHHnmEqVOnsm7dOt544w2ArlO9N954Iw0NDYwaNSrn6d/+0kxbhNLJhGbaRESkJGWeIs08NfrQQw9xzDHHMGfOHFasWNHtVGa23/zmN3zhC1+gsrKS8ePH8/nPf75r3RtvvMEnP/lJZs6cyf3338+KFSt6jWflypXU1NRw+OGHA3D++efz7LPPdq3/4he/CMCxxx7b9ZD5/Xn55Zepq6vjwAMPpKKignPPPZdnn32WQw89lNWrV3P55Zfzi1/8gvHjxwMwa9Yszj33XO677z4qKgafPGumLULpVIL6P2ygo8MpK7N8hyMiIqUoY0ZsxxA+e3T+/PlceeWVvPzyy2zfvp1jjz2WhoYGbr75Zl588UUmTpzIokWL2LlzYFUWFi1axCOPPMLRRx/N3XffTX19/aDiHTVqFADl5eW0tbUNal8TJ07k1Vdf5YknnuCHP/whDz30EHfddRePPfYYzz77LI8++iiLFy/m9ddfH1Typpm2CKWTCXar7IeIiJSgsWPHMm/ePL72ta91zbJt2bKFRCLBhAkTeO+993j88cd73cenPvUpHnnkEXbs2MHWrVt59NFHu9Zt3bqVgw8+mD179nD//fd3tY8bN46tW7fus68jjjiCxsZGVq1aBcC9997LSSedNKj3eOyxx/LMM8/Q3NxMe3s7DzzwACeddBLNzc10dHRw1llnccMNN/Dyyy/T0dHB2rVrmTdvHjfddBMtLS20trYO6viaaYtQOlUJQGPzNqYcMCbP0YiIiAythQsX8oUvfKHrNOnRRx/NnDlzOPLII5k6dSonnnhir9sfc8wxfPnLX+boo4/moIMO4rjjjuta9w//8A8cf/zxHHjggRx//PFdidqCBQu48MILufXWW7tuQAAYPXo0P/nJTzjnnHNoa2vjuOOO4+KLL+7X+3nyySepqqrqen333Xdz4403Mm/ePNyd008/nfnz5/Pqq6/y1a9+lY6ODgC++93v0t7eznnnnUdLSwvuzhVXXDHgO2Q7mXvxV/Cvra31zlowcamvr+fw2cdzwo1PccOZMzjvY9WxHq8U1NfXU1dXl+8wiobGM3oa02hpPAfurbfe4qMf/eg+7VuH8PRoKYhjPHN9dmb2krvXZvfV6dEIfWj8aEZVlLFGtdpEREQkYkraIlRWZqSTCRqaVfZDREREoqWkLWJBrTbNtImIiEi0lLRFrCaV4E8bt9PeUfzXCoqIyPBRCteoF5v+fmZK2iKWTiXY3d7B+pYd+Q5FRERKxOjRo9m4caMStwLi7mzcuJHRo0f3eRuV/IhYOpkAoLF5O1UTK/McjYiIlIKqqiqamprYsGFDt/adO3f2KymQ3kU9nqNHj+5WUmR/lLRFrLNWW8PGbXxiWirP0YiISCkYMWIENTU1+7TX19czZ86cPERUnPI9njo9GrHJ40YzekQZa/QMUhEREYmQkraIdZb90B2kIiIiEiUlbTGoTlbSoJk2ERERiZCSthikUwnWbtqhsh8iIiISGSVtMahJBmU/3v1AZT9EREQkGrEmbWZ2qpmtNLNVZnZ1jvWjzOzBcP3zZpYO25Nm9rSZtZrZ9zP6V5rZY2b2tpmtMLMb44x/oKo7y37oujYRERGJSGxJm5mVA7cBpwHTgYVmNj2r2wXAZnc/DLgFuCls3wl8G/irHLu+2d2PBOYAJ5rZaXHEPxg1qc5abUraREREJBpxzrTNBVa5+2p33w0sAeZn9ZkP3BMuPwycbGbm7tvc/bcEyVsXd9/u7k+Hy7uBl4G+V6UbIpPHj2LMiHIaN+rB8SIiIhKNOJO2KcDajNdNYVvOPu7eBrQAyb7s3MwOAP4CeHKwgUbNzIIHx2umTURERCJSkE9EMLMK4AHgVndf3UOfi4CLACZPnkx9fX2sMbW2tnY7RsJ3smJta+zHLWbZYyqDo/GMnsY0WhrP6GlMo5Xv8YwzaVsHTM14XRW25erTFCZiE4CNfdj3HcA77v69njq4+x1hP2pra72urq7PgQ9EfX09mcf43Y63ee23q/nkp06ivMxiPXaxyh5TGRyNZ/Q0ptHSeEZPYxqtfI9nnKdHXwSmmVmNmY0EFgBLs/osBc4Pl88GnnL3XoubmdkNBMndN6MNN1o1qUr2tLvKfoiIiEgkYptpc/c2M7sMeAIoB+5y9xVmdj2w3N2XAncC95rZKmATQWIHgJk1AuOBkWZ2JnAKsAX4W+Bt4GUzA/i+u/84rvcxUJ1lPxqatzF1UmWeoxEREZFCF+s1be6+DFiW1XZtxvJO4Jwetk33sNuCONfYWfZjzcZtwIH5DUZEREQKnp6IEJODxgVlPxqaVfZDREREBk9JW0y6yn7oqQgiIiISASVtMapJJVSrTURERCKhpC1G6VSCtZu309beke9QREREpMApaYtRTTIRlv3Yuf/OIiIiIr1Q0haj6mRQ6qNB17WJiIjIIClpi1H3sh8iIiIiA6ekLUYHjhtF5chyGnQzgoiIiAySkrYYBWU/dAepiIiIDJ6StpjVpCpZs1EFdkVERGRwlLTFLJ1M8KdNKvshIiIig6OkLWbpZIK2DmfdBzvyHYqIiIgUMCVtMUuHd5A26hSpiIiIDIKStpilU0GtNt2MICIiIoOhpC1mB44dRUJlP0RERGSQlLTFrKvshwrsioiIyCAoaRsCNamEyn6IiIjIoChpGwLpVCVrVfZDREREBkFJ2xCoDst+NG1W2Q8REREZGCVtQ6Cmq+yHrmsTERGRgVHSNgTSyTBp0x2kIiIiMkBK2oZAauxIEiPLVWBXREREBkxJ2xAwM9Iplf0QERGRgVPSNkTSqYROj4qIiMiAKWkbIulkJWs372CPyn6IiIjIAChpGyLpZIJ2lf0QERGRAVLSNkRU9kNEREQGQ0nbEEmnVPZDREREBk5J2xBJJkYydlSFkjYREREZECVtQyQo+1GpWm0iIiIyIErahlA6qVptIiIiMjBK2oZQOpmgSWU/REREZACUtA2hdEplP0RERGRglLQNoZpUJaA7SEVERKT/lLQNoepkUPajQUmbiIiI9JOStiGUTIxk3KgK3YwgIiIi/RZr0mZmp5rZSjNbZWZX51g/ysweDNc/b2bpsD1pZk+bWauZfT9rm2PN7PVwm1vNzOJ8D1EKyn4kVPZDRERE+i22pM3MyoHbgNOA6cBCM5ue1e0CYLO7HwbcAtwUtu8Evg38VY5d/wC4EJgWfp0affTxSacSuqZNRERE+i3Omba5wCp3X+3uu4ElwPysPvOBe8Llh4GTzczcfZu7/5YgeetiZgcD4939d+7uwL8BZ8b4HiKXTlbStHk7u9tU9kNERET6Ls6kbQqwNuN1U9iWs4+7twEtQHI/+2zazz6HtXQyQYdD02adIhUREZG+q8h3AHExs4uAiwAmT55MfX19rMdrbW3t0zE2b24HYOnTv2P2QUU7/JHo65hK32g8o6cxjZbGM3oa02jlezzjzBrWAVMzXleFbbn6NJlZBTAB2LiffVbtZ58AuPsdwB0AtbW1XldX15/Y+62+vp6+HGNm6y5ueP7XjDvkI9R9oibWmApdX8dU+kbjGT2NabQ0ntHTmEYr3+MZ5+nRF4FpZlZjZiOBBcDSrD5LgfPD5bOBp8Jr1XJy9/XAFjP7WHjX6FeA/x196PGZlBjJuNEVrFHZDxEREemH2Gba3L3NzC4DngDKgbvcfYWZXQ8sd/elwJ3AvWa2CthEkNgBYGaNwHhgpJmdCZzi7m8C/x9wNzAGeDz8KhhmRk0qoQK7IiIi0i+xXlTl7suAZVlt12Ys7wTO6WHbdA/ty4EZ0UU59KqTCV5ZuznfYYiIiEgB0RMR8qAmWcm6zTtU9kNERET6TElbHqRTQdmPtSr7ISIiIn2kpC0P0qngwfF6MoKIiIj0lZK2PEgng6RNNyOIiIhIXylpy4OJlSMYP7qCNXpwvIiIiPSRkrY86Cz70ahabSIiItJHStrypDqpWm0iIiLSd0ra8iSdSvDuBzvY1dae71BERESkAChpy5OaVGVQ9mPTjnyHIiIiIgVASVueVCdV9kNERET6TklbntR0Jm26GUFERET6QElbnkxMjGTCmBFK2kRERKRPlLTlUTqVoLFZtdpERERk/5S05VE6WamyHyIiItInStryKJ1M8G6Lyn6IiIjI/ilpy6OaVAJ3WLtJp0hFRESkd0ra8qg6WQlAg65rExERkf1Q0pZHNamg7Mca3UEqIiIi+6GkLY8OqBzJAZUjdDOCiIiI7JeStjyrTiZUq01ERET2S0lbntUkK1WrTURERPZLSVuepVNB2Y+de1T2Q0RERHqmpC3P0kmV/RAREZH9U9KWZ+nwDlLdjCAiIiK9UdKWZzXJzrIfmmkTERGRnilpy7MJlSOYWDmCBt1BKiIiIr1Q0jYMVCcTNOr0qIiIiPRCSdswUJNK6PSoiIiI9EpJ2zCQTqrsh4iIiPROSdswkE5V4g5/UtkPERER6YGStmEgHd5BquvaREREpCdK2oaBrqRNd5CKiIhID5S0DQNdZT/0DFIRERHpgZK2YSKdSrBGM20iIiLSAyVtw0SNarWJiIhIL5S0DRPpVIJ3W3aq7IeIiIjkFGvSZmanmtlKM1tlZlfnWD/KzB4M1z9vZumMddeE7SvN7LMZ7Vea2Qoze8PMHjCz0XG+h6FSnawE9AxSERERyS22pM3MyoHbgNOA6cBCM5ue1e0CYLO7HwbcAtwUbjsdWAAcBZwK3G5m5WY2BbgCqHX3GUB52K/g1aR0B6mIiIj0LM6ZtrnAKndf7e67gSXA/Kw+84F7wuWHgZPNzML2Je6+y90bgFXh/gAqgDFmVgFUAu/G+B6GTLVqtYmIiEgv4kzapgBrM143hW05+7h7G9ACJHva1t3XATcDfwLWAy3u/stYoh9iE8aMYFJipGbaREREJKeKfAfQH2Y2kWAWrgb4APipmZ3n7vfl6HsRcBHA5MmTqa+vjzW21tbWQR9j0og2Xlm1jvr6TdEEVeCiGFPZS+MZPY1ptDSe0dOYRivf4xln0rYOmJrxuipsy9WnKTzdOQHY2Mu2nwEa3H0DgJn9DDgB2Cdpc/c7gDsAamtrva6ubvDvqBf19fUM9hhL33+F//rjxkHvp1hEMaayl8YzehrTaGk8o6cxjVa+xzPO06MvAtPMrMbMRhLcMLA0q89S4Pxw+WzgKXf3sH1BeHdpDTANeIHgtOjHzKwyvPbtZOCtGN/DkEonE6xv2cmO3Sr7ISIiIt3FNtPm7m1mdhnwBMFdnne5+wozux5Y7u5LgTuBe81sFbCJ8E7QsN9DwJtAG3Cpu7cDz5vZw8DLYfvvCWfTikE6vIP0T5u2c8SHxuU5GhERERlOYr2mzd2XAcuy2q7NWN4JnNPDtouBxTnarwOuizbS4aEmvIO0oXmbkjYRERHpRk9EGEaqU0GBXd1BKiIiItmUtA0j40ePIJkYqVptIiIisg8lbcNMOpXQTJuIiIjsQ0nbMJNOJmhs1vNHRUREpDslbcNMOlnJn7eo7IeIiIh0p6RtmOks+7Fmk06RioiIyF5K2oaZmpQeHC8iIiL7UtI2zFQng7IfDbquTURERDIoaRtmxo0eQWrsSNboDlIRERHJoKRtGEonEzTo9KiIiIhk6FPSZmYJMysLlw83s8+b2Yh4QytdqtUmIiIi2fo60/YsMNrMpgC/BP4SuDuuoEpdOlnJe1t2sX13W75DERERkWGir0mbuft24IvA7e5+DnBUfGGVtq6yHxt1M4KIiIgE+py0mdnHgXOBx8K28nhCknRSZT9ERESku74mbd8ErgF+7u4rzOxQ4OnYoipxnTNtDbquTUREREIVfenk7s8AzwCENyQ0u/sVcQZWysaOqiA1dhRrVKtNREREQn29e/TfzWy8mSWAN4A3zeyv4w2ttNWkKjXTJiIiIl36enp0urtvAc4EHgdqCO4glZhUJxO6pk1ERES69DVpGxHWZTsTWOruewCPLSqhJpXg/a0q+yEiIiKBviZt/wtoBBLAs2ZWDWyJKyjJvINU17WJiIhIH5M2d7/V3ae4++c8sAaYF3NsJS2dCh4crycjiIiICPT9RoQJZvYvZrY8/Ppnglk3iUl150ybkjYRERGh76dH7wK2Al8Kv7YAP4krKAnKfhw4bpRuRhARERGgj3XagI+4+1kZr//ezF6JIR7JUJNM6Jo2ERERAfo+07bDzD7R+cLMTgR2xBOSdKpOqlabiIiIBPo603Yx8G9mNiF8vRk4P56QpFM6lWDDS01s29VGYlRfPyoREREpRn29e/RVdz8amAXMcvc5wKdjjUyoSelmBBEREQn09fQoAO6+JXwyAsB/jyEeyVCdDMt+6Lo2ERGRktevpC2LRRaF5JRW2Q8REREJDSZp02OsYpYYVcFBKvshIiIi7OdGBDPbSu7kzIAxsUQk3aSTCc20iYiISO9Jm7uPG6pAJLd0qpKnV27IdxgiIiKSZ4M5PSpDIJ1KsGHrLlp3teU7FBEREckjJW3DXE3nzQi6rk1ERKSkKWkb5vTgeBEREQElbcNeOhXUaluzUbXaRERESlmsSZuZnWpmK81slZldnWP9KDN7MFz/vJmlM9ZdE7avNLPPZrQfYGYPm9nbZvaWmX08zveQb5UjK5g8fhQNOj0qIiJS0mJL2sysHLgNOA2YDiw0s+lZ3S4ANrv7YcAtwE3httOBBcBRwKnA7eH+AP4V+IW7HwkcDbwV13sYLqqTCV3TJiIiUuLinGmbC6xy99XuvhtYAszP6jMfuCdcfhg42cwsbF/i7rvcvQFYBcwNH1j/KeBOAHff7e4fxPgehoWaZIJGnR4VEREpab3WaRukKcDajNdNwPE99XH3NjNrAZJh+++ytp0C7AA2AD8xs6OBl4BvuPs+01BmdhFwEcDkyZOpr6+P4C31rLW1NbZjdGzZTXPrHh7/9dOMqSidp4fFOaalSOMZPY1ptDSe0dOYRivf4xln0haHCuAY4HJ3f97M/hW4Gvh2dkd3vwO4A6C2ttbr6upiDay+vp64jrEjuZ6f/uFlpn70GGZMmRDLMYajOMe0FGk8o6cxjZbGM3oa02jlezzjPD26Dpia8boqbMvZx8wqgAnAxl62bQKa3P35sP1hgiSuqKVTKvshIiJS6uJM2l4EpplZjZmNJLixYGlWn6XA+eHy2cBT7u5h+4Lw7tIaYBrwgrv/GVhrZkeE25wMvBnjexgW0iqwKyIiUvJiOz0aXqN2GfAEUA7c5e4rzOx6YLm7LyW4oeBeM1sFbCJI7Aj7PUSQkLUBl7p7e7jry4H7w0RwNfDVuN7DcDFmZDkfGj+ahmbdjCAiIlKqYr2mzd2XAcuy2q7NWN4JnNPDtouBxTnaXwFqIw20AFQnK1mj06MiIiIlS09EKBA1qYSuaRMRESlhStoKRDqVoLl1N1t37sl3KCIiIpIHStoKRDoZPIO0Ude1iYiIlCQlbQVCZT9ERERKm5K2AlE9SWU/RERESpmStgLRVfZDM20iIiIlSUlbAUmnKlmjB8eLiIiUJCVtBaQmldDpURERkRKlpK2ApJMJNm7bzRaV/RARESk5StoKSHX4DNI1KvshIiJScpS0FZCasOyHbkYQEREpPUraCkh1V4FdJW0iIiKlRklbARk9opyDJ4xW0iYiIlKClLQVmHRSD44XEREpRUraCkw6laBRtdpERERKjpK2ApNOVrJp225adqjsh4iISClR0lZgOh8cv0anSEVEREqKkrYC01X2QzcjiIiIlBQlbQXmw5MqMYNGFdgVEREpKUraCszoEeUcPH60To+KiIiUGCVtBSidSuipCCIiIiVGSVsBSqcSKrArIiJSYpS0FaB0spLN2/fQsl1lP0REREqFkrYClE4Gd5DqyQgiIiKlQ0lbAeos+6GkTUREpHQoaStAU8OyH6rVJiIiUjqUtBWg0SPKOWTCGNboGaQiIiIlQ0lbgUqnKjXTJiIiUkKUtBWodDKha9pERERKiJK2ApVOJvhg+x4+2L4736GIiIjIEFDSVqDSXXeQ6ro2ERGRUqCkrUDVpCoB9GQEERGREqGkrUBVTQzKfui6NhERkdKgpK1AdZb90EybiIhIaVDSVsBqUgkadE2biIhISVDSVsCqk5WaaRMRESkRsSZtZnaqma00s1VmdnWO9aPM7MFw/fNmls5Yd03YvtLMPpu1XbmZ/d7M/k+c8Q93NakELTtU9kNERKQUxJa0mVk5cBtwGjAdWGhm07O6XQBsdvfDgFuAm8JtpwMLgKOAU4Hbw/11+gbwVlyxF4p0Mij7oScjiIiIFL84Z9rmAqvcfbW77waWAPOz+swH7gmXHwZONjML25e4+y53bwBWhfvDzKqA04Efxxh7QUh3lv3QHaQiIiJFryLGfU8B1ma8bgKO76mPu7eZWQuQDNt/l7XtlHD5e8C3gHG9HdzMLgIuApg8eTL19fUDeQ991traGvsxsu3pcAyoX/4mE1tWDemxh0I+xrSYaTyjpzGNlsYzehrTaOV7PONM2iJnZmcA77v7S2ZW11tfd78DuAOgtrbW6+p67T5o9fX1xH2MXKa8+BSMm0hd3ZwhP3bc8jWmxUrjGT2NabQ0ntHTmEYr3+MZ5+nRdcDUjNdVYVvOPmZWAUwANvay7YnA582skeB066fN7L44gi8UNamE7iAVEREpAXEmbS8C08ysxsxGEtxYsDSrz1Lg/HD5bOApd/ewfUF4d2kNMA14wd2vcfcqd0+H+3vK3c+L8T0Me9XJSj1/VEREpATEdno0vEbtMuAJoBy4y91XmNn1wHJ3XwrcCdxrZquATQSJGGG/h4A3gTbgUndvjyvWQpZOBmU/Nm/bzcTEyHyHIyIiIjGJ9Zo2d18GLMtquzZjeSdwTg/bLgYW97LveqA+ijgLWU0qLPuxcZuSNhERkSKmJyIUuOqwVpuuaxMRESluStoK3IcnVVJm6Lo2ERGRIqekrcCNrChjysQxmmkTEREpckraikA6mdBTEURERIqckrYikE4maGjeRlAtRURERIqRkrYikE4l2Lqzjc3b9+Q7FBEREYmJkrYiUBM+OL5B17WJiIgULSVtRaCz7McaXdcmIiJStJS0FYGpE8OyH5ppExERKVpK2orAyIoyqiZW0qBabSIiIkVLSVuRqE5WaqZNRESkiClpKxI1qaBWm8p+iIiIFCclbUUinQzKfmzatjvfoYiIiEgMlLQViXRY9kNPRhARESlOStqKRDos+9HYrJsRREREipGStiIxdVIl5WWmmTYREZEipaStSIwoL6Nq4hg9FUFERKRIKWkrItXJBGtUq01ERKQoKWkrIjVhrTaV/RARESk+StqKSDqVYOuuNjaq7IeIiEjRUdJWRNJ6cLyIiEjRUtJWRNKpIGlrUNkPERGRoqOkrYhUTRwTlP3QHaQiIiJFR0lbEekq+6HToyIiIkVHSVuRSScTuqZNRESkCClpKzI1qQSNzdtV9kNERKTIKGkrMulkJa272mhuVdkPERGRYqKkrchUp1T2Q0REpBgpaSsyNcnOsh9K2kRERIqJkrYiUzVxDBVlRqNm2kRERIqKkrYiUxGW/WjUg+NFRESKipK2IpROJVRgV0REpMgoaStC6WSQtKnsh4iISPFQ0laE0slKtu1uZ0PrrnyHIiIiIhFR0laE0l1lP3Rdm4iISLFQ0laEalIq+yEiIlJsYk3azOxUM1tpZqvM7Ooc60eZ2YPh+ufNLJ2x7pqwfaWZfTZsm2pmT5vZm2a2wsy+EWf8hWrKAWHZDyVtIiIiRSO2pM3MyoHbgNOA6cBCM5ue1e0CYLO7HwbcAtwUbjsdWAAcBZwK3B7urw34H+4+HfgYcGmOfZa8ivIypk6q1OlRERGRIhLnTNtcYJW7r3b33cASYH5Wn/nAPeHyw8DJZmZh+xJ33+XuDcAqYK67r3f3lwHcfSvwFjAlxvdQsNLJSp0eFRERKSIVMe57CrA243UTcHxPfdy9zcxagGTY/rusbbslZ+Gp1DnA87kObmYXARcBTJ48mfr6+gG+jb5pbW2N/Rj9UbFzF398v42nn36aIA8uPMNtTAudxjN6GtNoaTyjpzGNVr7HM86kLTZmNhb4D+Cb7r4lVx93vwO4A6C2ttbr6upijam+vp64j9Efa0Y28qs1Kziq9uMcNG50vsMZkOE2poVO4xk9jWm0NJ7R05hGK9/jGefp0XXA1IzXVWFbzj5mVgFMADb2tq2ZjSBI2O5395/FEnkR6Cz70dis69pERESKQZxJ24vANDOrMbORBDcWLM3qsxQ4P1w+G3jKgzL+S4EF4d2lNcA04IXwerc7gbfc/V9ijL3g1SQ7kzZd1yYiIlIMYjs9Gl6jdhnwBFAO3OXuK8zsemC5uy8lSMDuNbNVwCaCxI6w30PAmwR3jF7q7u1m9gngL4HXzeyV8FB/4+7L4nofheqQA0ZTUWY0bFTSJiIiUgxivaYtTKaWZbVdm7G8Ezinh20XA4uz2n4LFOZV9UOsoryMD0+qZI2SNhERkaKgJyIUsXQqQYOuaRMRESkKStqKWHUymGkLLhMUERGRQqakrYjVpBJs393Ohq278h2KiIiIDJKStiKWTurB8SIiIsVCSVsRq+ms1aabEURERAqekrYidvCE0YwoNxr14HgREZGCp6StiFWUlzF1UqUK7IqIiBQBJW1FriaZ0DVtIiIiRUBJW5GrTiZYs3G7yn6IiIgUOCVtRa4mVcmOPe28r7IfIiIiBU1JW5FLp1T2Q0REpBgoaStynbXadDOCiIhIYVPSVuQOOWAMI8vLVPZDRESkwClpK3LlZcbUSWM00yYiIlLglLSVgJpUQk9FEBERKXBK2kpAdTJI2lT2Q0REpHApaSsB6VSCnXs6eG+Lyn6IiIgUKiVtJaAmqbIfIiIihU5JWwmoTlYCsEbXtYmIiBQsJW0loLPsR4OSNhERkYKlpK0ElJcZH05WquyHiIhIAVPSViLSyUoam1VgV0REpFApaSsR6WSCNZu20dGhsh8iIiKFSElbiegq+7F1Z75DERERkQFQ0lYialIq+yEiIlLIlLSViL1lP3Rdm4iISCFS0lYiDpkwhpEVZbqDVEREpEApaSsRZWVG9aRKnR4VEREpUEraSkh1MqHToyIiIgWqIt8ByNCpSVXym3c2cP/za/Cw8kdXAZCwwTNeeo627q/3lg/Zu8736dvTur3b+r7xAA0Nu3m9/R3MwMyCf+n8l+6vzTLaMvv3vi0GZZnbZvSDcF2ObQlfd27bV9aPzn3t29cIXtvQhr/9ftdrp/sHse/nsu8+sps8q9O+6/e3h9zH2Z++jU3vnfqyj/11WfF+G3vefC/j+yLjeyvcQec+LON7JbOPZfShh/bO7+HOmCxjg+7ttk+fzO/nrq0y1nUdK0dbruPtu84y1vTxuFlj0dl/884O1rfsAMLfQWGfzN8Rnesg+B7u/rvGM5a7evf4+6hr2XP/fsrVnvntmv17KPN97v3dlOv3R/iOM39H9bavHOutMwCy99+977Y9TsuOPVlj3bnvvQfK9XmQ1Zbrda7vl739LEfbvsfO1vU55vg/Z9//j3J/brnWZX+PdNuuh+8psrbZssvp6HDKyvrzmz86Stqi0PwO41tWQtO48KemLPjCwmXroc362C/8l4z1+2yb3XdfR089gF2/aeBvf/7GUI3M4K36Qz83cMpwyujAIPy3e5vREb4OviyjbxlOmXlXH+vq0/N+gfCVde0t89/O5Y6wt1NGh+fus7dvZ6R7t+sIJ8Y7uo6+t1+fvfRiP8dT9uvl5fmOoLjUPzUEB8n8mfZ9fk/s/ZnvyPg94d1+R7jv/Vns/Dnd+/Pavc27rQ9e9+vndrCe/OXQHaubfX9/Allj7Bm/BYPfp10JZDhSncud++zss7d/L21dw5x7/z0dZ+/x2Ge7Ez4+l9T4xEAGZNCUtEXhV9dyzMpl8Pt8B5LJ9knuzrAyTh9ruGX161rs/leXZ/6t1S0RzL1Nr+t62r6XdXt272LEiArwjowvD78y2ghem3dQqpy9n7NnJPme8UdAW3s75RXZP/K9fRY51velT7/X55p/y5j6yVr2fdZlHsfwzHVdUxHZ69hnHRCuz9xub7+9x9273bbWVhKJsV3vwCFr6jBjKifXu801PdBjn73HsIwZB8uYM+2pPXuXmGWNeffPpKd1nuv7obO/Wfews34XeGZn27uc+Zns3LmTMaNGBv9JepjiuIc/28G/nW10rqMD8/aMtu7r923rIPvd54N3/nyG/3Zbpiwcs7JwXfCnome2hT/zntnetf3e/ezetZPRI0d0HjEc1+D3aPZY7h3jjOXO9t76kPkZ7f0TtFjtaJ8PKGkrXCddxWsja5k1c2a3JGJvkpHZ5jnacvXL6Jur3373mbtf8AOWwz7nqDJ+5fblP5xe1w1smw3r/8yUKVW9zChmL2d8df4H2609V9/sGcye+uaa2cyY1ezxc+nox2fYn77dP2/L6Gu5voe8g/VNa6mqqurbZ5FzfV/69HN9T30yExXPbs9MhLKWu22XvdzTdgx4Hzv3QOX4SUHbfv+w6cMfMX3+42gA++jS22fUl++B/m7X93UbN25kUurA/f9851xf3oef4/3to6/rO3/uw5+zjvZ9f15zfu1db10/tz332d8+9t+nneZNm0kmUxnvJdcZnVxneno7A1S27/pe99WHY+f4o6hL9s9QD3/Q7V2Xo9+A1u3bb8Wbb3HU2APIFyVtUThkNpuSH8DhdfmOpKi8U1/PlLq6fIdRNFbV11Ol8YzUa/X11GlMI/O6xjNyb2hMI7WhuR5GjM7b8XX3qIiIiEgBiDVpM7NTzWylma0ys6tzrB9lZg+G6583s3TGumvC9pVm9tm+7lNERESkGMWWtJlZOXAbcBowHVhoZtOzul0AbHb3w4BbgJvCbacDC4CjgFOB282svI/7FBERESk6cc60zQVWuftqd98NLAHmZ/WZD9wTLj8MnGxB8Zb5wBJ33+XuDcCqcH992aeIiIhI0YkzaZsCrM143RS25ezj7m1AC5DsZdu+7FNERESk6BTt3aNmdhFwEcDkyZOpr6+P9Xitra2xH6PUaEyjpfGMnsY0WhrP6GlMo5Xv8YwzaVsHTM14XRW25erTZGYVwARg43623d8+AXD3O4A7AGpraz3uW57rdVt15DSm0dJ4Rk9jGi2NZ/Q0ptHK93jGeXr0RWCamdWY2UiCGwuWZvVZCpwfLp8NPOXBQ76WAgvCu0trgGnAC33cp4iIiEjRiW2mzd3bzOwy4AmgHLjL3VeY2fXAcndfCtwJ3Gtmq4BNBEkYYb+HgDeBNuBSd28HyLXPuN6DiIiIyHAR6zVt7r4MWJbVdm3G8k7gnB62XQws7ss+RURERIqdnoggIiIiUgCUtImIiIgUACVtIiIiIgXAgps1i5uZbQDWxHyYFNAc8zFKjcY0WhrP6GlMo6XxjJ7GNFpDNZ7V7n5gdmNJJG1DwcyWu3ttvuMoJhrTaGk8o6cxjZbGM3oa02jlezx1elRERESkAChpExERESkAStqic0e+AyhCGtNoaTyjpzGNlsYzehrTaOV1PHVNm4iIiEgB0EybiIiISAFQ0hYBMzvVzFaa2Sozuzrf8RQyM5tqZk+b2ZtmtsLMvpHvmIqBmZWb2e/N7P/kO5ZiYGYHmNnDZva2mb1lZh/Pd0yFzsyuDH/m3zCzB8xsdL5jKjRmdpeZvW9mb2S0TTKzX5nZO+G/E/MZYyHpYTz///Dn/jUz+7mZHTCUMSlpGyQzKwduA04DpgMLzWx6fqMqaG3A/3D36cDHgEs1npH4BvBWvoMoIv8K/MLdjwSORmM7KGY2BbgCqHX3GUA5sCC/URWku4FTs9quBp5092nAk+Fr6Zu72Xc8fwXMcPdZwB+Aa4YyICVtgzcXWOXuq919N7AEmJ/nmAqWu69395fD5a0E/xlOyW9Uhc3MqoDTgR/nO5ZiYGYTgE8BdwK4+253/yCvQRWHCmCMmVUAlcC7eY6n4Lj7s8CmrOb5wD3h8j3AmUMZUyHLNZ7u/kt3bwtf/g6oGsqYlLQN3hRgbcbrJpRkRMLM0sAc4Pk8h1Lovgd8C+jIcxzFogbYAPwkPOX8YzNL5DuoQubu64CbgT8B64EWd/9lfqMqGpPdfX24/Gdgcj6DKTJfAx4fygMqaZNhyczGAv8BfNPdt+Q7nkJlZmcA77v7S/mOpYhUAMcAP3D3OcA2dMppUMLrrOYTJMSHAAkzOy+/URUfD8pFqGREBMzsbwku57l/KI+rpG3w1gFTM15XhW0yQGY2giBhu9/df5bveArcicDnzayR4NT9p83svvyGVPCagCZ375wBfpggiZOB+wzQ4O4b3H0P8DPghDzHVCzeM7ODAcJ/389zPAXPzBYBZwDn+hDXTVPSNngvAtPMrMbMRhJcPLs0zzEVLDMzgmuF3nL3f8l3PIXO3a9x9yp3TxN8bz7l7prBGAR3/zOw1syOCJtOBt7MY0jF4E/Ax8ysMvwdcDK6uSMqS4Hzw+Xzgf+dx1gKnpmdSnC5yefdfftQH19J2yCFFyReBjxB8EvmIXdfkd+oCtqJwF8SzAi9En59Lt9BiWS5HLjfzF4DZgP/mN9wCls4a/kw8DLwOsH/Tark309m9gDwX8ARZtZkZhcANwL/zczeIZjRvDGfMRaSHsbz+8A44Ffh/08/HNKY9EQEERERkeFPM20iIiIiBUBJm4iIiEgBUNImIiIiUgCUtImIiIgUACVtIiIiIgVASZuIlDwza88oMfOKmUX2hAMzS5vZG1HtT0RKV0W+AxARGQZ2uPvsfAchItIbzbSJiPTAzBrN7J/M7HUze8HMDgvb02b2lJm9ZmZPmtmHw/bJZvZzM3s1/Op8FFO5mf3IzFaY2S/NbEze3pSIFCwlbSIiMCbr9OiXM9a1uPtMgkro3wvb/idwj7vPInhg9K1h+63AM+5+NMHzSDufjjINuM3djwI+AM6K9d2ISFHSExFEpOSZWau7j83R3gh82t1Xm9kI4M/unjSzZuBgd98Ttq9395SZbQCq3H1Xxj7SwK/cfVr4+ipghLvfMARvTUSKiGbaRER65z0s98eujOV2dD2xiAyAkjYRkd59OePf/wqXnwMWhMvnAr8Jl58ELgEws3IzmzBUQYpI8dNfeyIi4TVtGa9/4e6dZT8mmtlrBLNlC8O2y4GfmNlfAxuAr4bt3wDuMLMLCGbULgHWxx28iJQGXdMmItKD8Jq2WndvzncsIiI6PSoiIiJSADTTJiIiIlIANNMmIiIiUgCUtImIiIgUACVtIiIiIgVASZuIiIhIAVDSJiIiIlIAlLSJiIiIFID/C/SUjqcTIrRCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model_save_path = 'best_steering_model_v1.pth'\n",
    "model, history = train_steering_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    model_save_path=model_save_path\n",
    ")\n",
    "\n",
    "# Later, when you need to load the model for self-driving:\n",
    "model = NVIDIANet(num_outputs=1)\n",
    "model = load_model(model, model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
