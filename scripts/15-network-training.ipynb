{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26018 valid files\n",
      "Split into 20815 training and 5203 validation samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def get_carla_data_files(data_dir: str, min_timestamp: str = None) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Get all valid training files from the Carla dataset directory and their steering angles.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the carla_dataset directory\n",
    "        min_timestamp: Minimum timestamp to include (as string), optional\n",
    "                      If None, includes all valid files\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing (file_path, steering_angle)\n",
    "    \"\"\"\n",
    "    # Get all jpg files in directory\n",
    "    pattern = os.path.join(data_dir, \"*.jpg\")\n",
    "    all_files = glob.glob(pattern)\n",
    "    valid_files = []\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        # Get filename without extension\n",
    "        filename = os.path.basename(file_path)\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        # Check if filename matches expected pattern\n",
    "        if len(parts) >= 5 and 'steering' in filename:\n",
    "            # Extract timestamp and steering\n",
    "            timestamp = '_'.join(parts[0:3])  # Combine timestamp parts\n",
    "            try:\n",
    "                steering = float(parts[-1].replace('.jpg', ''))\n",
    "                \n",
    "                # Only include files with timestamp >= min_timestamp if specified\n",
    "                if min_timestamp is None or timestamp >= min_timestamp:\n",
    "                    valid_files.append((file_path, steering))\n",
    "            except ValueError:\n",
    "                continue  # Skip if steering value can't be converted to float\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    valid_files.sort(key=lambda x: os.path.basename(x[0]).split('_')[0:3])\n",
    "    return valid_files\n",
    "\n",
    "def train_val_split(file_pairs: List[Tuple[str, float]], val_ratio: float = 0.2) -> Tuple[List[Tuple[str, float]], List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training and validation sets.\n",
    "    \n",
    "    Args:\n",
    "        file_pairs: List of (file_path, steering_angle) tuples\n",
    "        val_ratio: Ratio of validation set size to total dataset size\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_pairs, val_pairs)\n",
    "    \"\"\"\n",
    "    # Create random indices\n",
    "    num_samples = len(file_pairs)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    split_idx = int(np.floor(val_ratio * num_samples))\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    val_indices = indices[:split_idx]\n",
    "    train_indices = indices[split_idx:]\n",
    "    \n",
    "    train_pairs = [file_pairs[i] for i in train_indices]\n",
    "    val_pairs = [file_pairs[i] for i in val_indices]\n",
    "    \n",
    "    return train_pairs, val_pairs\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Run with 1920 x 1080 images\n",
    "\n",
    "    # Test the functions\n",
    "    #data_dir = \"/home/daniel/git/carla-driver-data/scripts/wip/carla_dataset_1920x1080/\"\n",
    "    data_dir = \"/home/daniel/git/carla-driver-data/scripts/wip/config_640x480_laneid_1/\"\n",
    "    files = get_carla_data_files(data_dir)\n",
    "    print(f\"Found {len(files)} valid files\")\n",
    "    \n",
    "    train_files, val_files = train_val_split(files)\n",
    "    print(f\"Split into {len(train_files)} training and {len(val_files)} validation samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "class CarlaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Carla steering angle prediction.\n",
    "    Handles loading and preprocessing of images, and conversion to tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 file_pairs: List[Tuple[str, float]], \n",
    "                #  crop_top: int = 460,\n",
    "                #  crop_bottom: int = 1080,\n",
    "                 crop_top: int = 210,\n",
    "                 crop_bottom: int = 400,                \n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            file_pairs: List of tuples containing (image_path, steering_angle)\n",
    "            crop_top: Y coordinate where crop begins\n",
    "            crop_bottom: Y coordinate where crop ends\n",
    "            transform: Optional additional transformations\n",
    "        \"\"\"\n",
    "        self.file_pairs = file_pairs\n",
    "        self.crop_top = crop_top\n",
    "        self.crop_bottom = crop_bottom\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_pairs)\n",
    "    \n",
    "    def prepare_image_for_neural_network(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Load image, crop, resize, and convert to YUV for neural network processing.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the input image\n",
    "            \n",
    "        Returns:\n",
    "            numpy array in YUV format, size 66x200x3\n",
    "        \"\"\"\n",
    "        # Read and convert image\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Crop\n",
    "        cropped = img_rgb[self.crop_top:self.crop_bottom, :]\n",
    "        \n",
    "        # Resize to neural network input size (66x200)\n",
    "        resized = cv2.resize(cropped, (200, 66))\n",
    "        \n",
    "        # Convert to YUV\n",
    "        yuv = cv2.cvtColor(resized, cv2.COLOR_RGB2YUV)\n",
    "        \n",
    "        return yuv\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get a sample from the dataset.\n",
    "        \n",
    "        Args:\n",
    "            idx: Index of the sample to get\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (image, steering_angle) where image is a preprocessed torch tensor\n",
    "                  and steering_angle is a torch tensor\n",
    "        \"\"\"\n",
    "        image_path, steering_angle = self.file_pairs[idx]\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = self.prepare_image_for_neural_network(image_path)\n",
    "        \n",
    "        # Convert to torch tensor and adjust dimensions for PyTorch (CHW instead of HWC)\n",
    "        image_tensor = torch.from_numpy(image).float()\n",
    "        image_tensor = image_tensor.permute(2, 0, 1)  # Change from HWC to CHW format\n",
    "        \n",
    "        # Convert steering angle to tensor\n",
    "        steering_tensor = torch.tensor(steering_angle, dtype=torch.float32)\n",
    "        \n",
    "        # Apply any additional transforms if specified\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image_tensor)\n",
    "            \n",
    "        return image_tensor, steering_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 26018\n",
      "Training samples: 20815, Validation samples: 5203\n",
      "Batch image shape: torch.Size([64, 3, 66, 200])\n",
      "Batch steering shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Example usage in Jupyter notebook:\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Get file pairs\n",
    "data_dir = \"/home/daniel/git/carla-driver-data/scripts/wip/config_640x480_laneid_1/\"  # adjust path as needed\n",
    "file_pairs = get_carla_data_files(data_dir)\n",
    "print(f\"Total number of samples: {len(file_pairs)}\")\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_pairs, val_pairs = train_val_split(file_pairs)\n",
    "print(f\"Training samples: {len(train_pairs)}, Validation samples: {len(val_pairs)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CarlaDataset(train_pairs)\n",
    "val_dataset = CarlaDataset(val_pairs)\n",
    "\n",
    "# Create dataloaders with appropriate num_workers for Jupyter\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)  # num_workers=0 for Jupyter\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "# Test loading a single batch\n",
    "images, steering = next(iter(train_loader))\n",
    "print(f\"Batch image shape: {images.shape}\")  # Should be [batch_size, 3, 66, 200]\n",
    "print(f\"Batch steering shape: {steering.shape}\")  # Should be [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NVIDIANet(nn.Module):\n",
    "    def __init__(self, num_outputs=1, dropout_rate=0.1):\n",
    "        super(NVIDIANet, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 32, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 48, kernel_size=5, stride=2)\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1152, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input normalization\n",
    "        x = x / 255.0\n",
    "        \n",
    "        # Convolutional layers with ELU activation and dropout\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.elu(self.conv5(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        x = self.flatten(x)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_state_dict = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_state_dict = model.state_dict().copy()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_state_dict = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "            return True  # Indicates we have a new best model\n",
    "        return False  # Indicates this is not a new best model\n",
    "\n",
    "def train_model(model, train_loader, val_loader, model_save_path, num_epochs=100, device=\"cuda\", learning_rate=1e-5):\n",
    "    \"\"\"Training loop with validation and early stopping\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    early_stopping = EarlyStopping(patience=6)\n",
    "    \n",
    "    # History for plotting\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for images, steering in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images = images.to(device)\n",
    "            steering = steering.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), steering)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, steering in val_loader:\n",
    "                images = images.to(device)\n",
    "                steering = steering.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs.squeeze(), steering)\n",
    "                val_losses.append(val_loss.item())\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        \n",
    "        # Save to history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        is_best = early_stopping(avg_val_loss, model)\n",
    "        \n",
    "        # Save if it's the best model\n",
    "        if is_best:\n",
    "            print(f\"New best model! Saving to {model_save_path}\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "            }, model_save_path)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            print(f\"Loading best model from {model_save_path}\")\n",
    "            model.load_state_dict(early_stopping.best_state_dict)\n",
    "            break\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def load_model(model, model_path, device='cuda'):\n",
    "    \"\"\"Load a saved model\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss During Training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.savefig('training_history.png')\n",
    "    \n",
    "\n",
    "def train_steering_model(train_dataset, val_dataset, model_save_path, batch_size=64):\n",
    "    \"\"\"Full training pipeline\"\"\"\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = NVIDIANet(num_outputs=1)\n",
    "    \n",
    "    # Train model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    trained_model, history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        model_save_path=model_save_path,\n",
    "        num_epochs=100,\n",
    "        device=device,\n",
    "        learning_rate=1e-5\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return trained_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \n",
    "NB With GeForce RTX 3060:  \n",
    "pip install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "To work with python 3.6.9 in carla-env environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5832b4baddb7476e8602416f0c437394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.0002, Val Loss: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5d32b4ef534489a748504e82bf5da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ea9aac556a41df8b9782eca454bb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5bab4aafcb406383276a08246ec762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c300184f0e479db67223999bc41f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c433521b004e4c61b189ebbfcf3d50f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd187f5983b34e3e9778f32e835d807c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7278493a13458294bfdd336e1ed829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b368a4fde04fa7906eb12c78b4b878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a258a94b69f14966bfdb2bd0fd77f3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ff22c57c9b4e4a80a9fab1240faea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9f798643854a30a0509572abb1d51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f4570c29f941c997c8ef01feee5659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da1ec383ad7401d8a5273c704746e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f083edb9ad5044249aeb6b4de01f6c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d475bf64860b4d45b808d1a8040701ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d83161c30845a7b5bfcc161daea621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242b2901d2ae4e78a0cf350c7675dd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6b1979b13947cebd239e00e07aa099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec512e20f5645058dea9dbbd0225f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a429c5c5569943329a12d6cad3702d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf76ede69f344e9825c3b70a6fe386e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfadcf3cdd64f30bfccadbe56d0da86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248f1a713b134052a9f08f9568a7f621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4316d8b0405f4123b53887146fd90219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd1826fc3294b00a7293c85b63170b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8cdc3525554666b894df0d63aff1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "New best model! Saving to best_steering_model_20250329-153940.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a03045526f4ef280f4b727aec31c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/100:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "# add a timestamp to the model save path\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_save_path = f'best_steering_model_{timestamp}.pth'\n",
    "\n",
    "model, history = train_steering_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    model_save_path=model_save_path\n",
    ")\n",
    "\n",
    "# Later, when you need to load the model for self-driving:\n",
    "model = NVIDIANet(num_outputs=1)\n",
    "model = load_model(model, model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
